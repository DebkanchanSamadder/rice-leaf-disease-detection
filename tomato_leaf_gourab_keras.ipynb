{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e06cff-5fbb-41a4-bf03-dbfa4f110d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "DATASET_DIR= r'C:/Users/Gourab Paul/CollegeProject/tomato'\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_SHAPE=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
    "NUM_CLASSES=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55806ce1-4bae-474a-966b-0af55865856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    F\"{DATASET_DIR}/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    # image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.image_dataset_from_directory(\n",
    "    F\"{DATASET_DIR}/train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    # image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689b9ac-4579-4e7c-be6c-83c256f16218",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "    keras.layers.RandomTranslation(0.2, 0.2),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    # keras.layers.RandomBrightness(0.4),\n",
    "    keras.layers.RandomContrast(0.4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82610839-629c-49b7-9cde-0c02a8e775c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = keras.Sequential([\n",
    "    # keras.layers.Reshape(IMAGE_SHAPE),\n",
    "    keras.layers.Resizing(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    keras.layers.Rescaling(1./255),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc43a0d-874e-4bd7-a1d9-d4c508716069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTOTUNE = tf.data.AUTOTUNE\n",
    "# train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "# train_ds.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdd755-e386-40f7-91bc-a74e62706861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=(None,None,3)),\n",
    "\n",
    "    preprocessing,\n",
    "    # data_augmentation,\n",
    "\n",
    "    keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "\n",
    "    keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    keras.layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    \n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    \n",
    "    # tf.keras.layers.Flatten(),\n",
    "\n",
    "    # keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    # keras.layers.Dense(128, activation=\"relu\"),\n",
    "    # keras.layers.Dropout(0.4),\n",
    "\n",
    "    keras.layers.Dense(NUM_CLASSES, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7fa35-a84a-4026-9a1e-d11b69f3162d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=300,\n",
    "    # steps_per_epoch=train_ds.samples/train_ds.batch_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[earlystop]\n",
    "    # validation_steps=validation_ds.samples/validation_ds.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b429d-50f5-4ae2-929f-5a2a1ff19b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = keras.utils.image_dataset_from_directory(\n",
    "    F\"{DATASET_DIR}/val\",\n",
    "    # image_size=(IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    ")\n",
    "results = model.evaluate(test_ds, verbose=0)\n",
    "print(\"test accuracy:\", results[1]*100)\n",
    "print(\"test loss:\", results[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81b406a-8c07-409c-8cd3-4cd278c9766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "acc = history.history[\"sparse_categorical_accuracy\"]\n",
    "val_acc = history.history[\"val_sparse_categorical_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# Train and validation accuracy\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "# plt.ylim((0, 1))\n",
    "plt.plot(epochs, acc, \"b\",label=\"Training accurarcy\")\n",
    "plt.plot(epochs, val_acc, \"r\", label=\"Validation accurarcy\")\n",
    "plt.title(\"Training and Validation accurarcy\")\n",
    "plt.legend()\n",
    "\n",
    "# Train and validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "plt.title(\"Training and Validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e51aea5-d3fd-4c06-a798-06e2660921ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "correct = 0\n",
    "inCorrect = 0\n",
    "classNames = [\n",
    "    \"Tomato___Bacterial_spot\", \n",
    "    \"Tomato___Early_blight\",\n",
    "    \"Tomato___healthy\",\n",
    "    \"Tomato___Late_blight\",\n",
    "    \"Tomato___Leaf_Mold\",\n",
    "    \"Tomato___Septoria_leaf_spot\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "    \"Tomato___Target_Spot\",\n",
    "    \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "]\n",
    "\n",
    "def predict(image, label):\n",
    "    result = model.predict(image)*100\n",
    "    predictedClass = classNames[result.argmax()]\n",
    "\n",
    "    boolResult = False\n",
    "    if str(classNames[label]) == predictedClass:\n",
    "        boolResult = True\n",
    "    # print(f\"\\n{classNames[label]} --- Label {label} --- Result {predictedClass} --- Correct?? {boolResult}\")\n",
    "    return boolResult\n",
    "\n",
    "valDS = keras.utils.image_dataset_from_directory(\n",
    "    F\"{DATASET_DIR}/val\",\n",
    "    # image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "for image, label in valDS:\n",
    "    result = predict(image, label[0])\n",
    "    if(result==True):\n",
    "        correct += 1\n",
    "    else:\n",
    "        inCorrect += 1\n",
    "    # break\n",
    "print(f\"\\n[INFO] Correct ---> {correct}           InCorrect ---> {inCorrect}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbba04f-65bf-4fcf-beab-e9a97898ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('tomato_feel_bad(32,64,128_GA,D20)_E103.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196a178-c199-46de-9df8-44a61265420e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
